{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.9.6' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Path to the PDF file\n",
    "pdf_path = 'sssv1.pdf'\n",
    "\n",
    "newfile = open(\"txtfile.txt\",\"w\")\n",
    "\n",
    "# Open the PDF file\n",
    "with open(pdf_path, 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    num_pages = len(reader.pages)\n",
    "    \n",
    "    # Iterate through all pages and extract text\n",
    "    for page_num in range(num_pages):\n",
    "        page = reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        newfile.write(text)\n",
    "        #print(text)\n",
    "        #print(\"-\" * 40)\n",
    "newfile.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"txtfile.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370044"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sri Sathya Sai Speaks, Vol 1 (1953 - 60)\n",
      "Divine Discourses of Bhagawan Sri Sathya Sai BabaIndex Of Discourses\n",
      "1.   Have You Heard Our Baba Speak? ....................................................................... 2\n",
      "1.   Worship In The Mind .............................................................................................. 7\n",
      "2.   Total Surrender ...................................................................................................... 13\n",
      "3.   God As Guide ......................................................................................................... 20\n",
      "4.   Divine Life .............................................................................................................. 25\n",
      "5.   Meditation On The Lord's Name And Form ...................................................... 27\n",
      "6.   An Attitude Of Challenge ...................................................................................... 33\n",
      "7.   Courage ......................................\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[ch] for ch in s]\n",
    "decode = lambda s: ''.join([itos[ch] for ch in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sairam'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode(\"sairam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suriya/personal/swami-bot/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[82, 958, 321]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "enc.encode(\"sairam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sairam'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode([82,958,321])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42, 67, 58,  1, 42, 50, 69, 57, 74])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size=8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split==\"train\" else val_data\n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        F.cross_entropy(logits, targets)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "\n",
    "model = BigramLanguageModel(vocab_size=vocab_size)\n",
    "x, y = get_batch(\"train\")\n",
    "logits = model.forward(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6138, -2.5856,  0.2490,  ...,  0.6676,  1.3981,  0.8418],\n",
       "         [ 0.3258, -0.1532, -0.2287,  ..., -0.5760,  0.4606,  0.1399],\n",
       "         [-0.6913,  1.6817, -2.8799,  ..., -0.4001, -0.6220,  0.8666],\n",
       "         ...,\n",
       "         [ 1.3926, -0.5535,  0.1462,  ...,  1.1940,  0.8662,  0.2340],\n",
       "         [-1.1549,  1.7132, -0.9407,  ..., -0.7629, -0.1129, -0.0632],\n",
       "         [-1.6768,  1.1494,  0.3669,  ...,  0.2473, -0.8296, -1.1125]],\n",
       "\n",
       "        [[-1.2891,  1.4083, -0.1987,  ...,  1.2387,  0.9744,  0.0670],\n",
       "         [-1.2245,  1.3634, -2.2474,  ..., -0.2318,  2.1367, -1.1016],\n",
       "         [-0.6913,  1.6817, -2.8799,  ..., -0.4001, -0.6220,  0.8666],\n",
       "         ...,\n",
       "         [-0.6798, -0.6323, -0.1855,  ...,  0.9329, -0.2530,  0.0529],\n",
       "         [ 0.9969, -0.2586, -1.0324,  ..., -0.9481, -0.8290, -0.1003],\n",
       "         [-0.6913,  1.6817, -2.8799,  ..., -0.4001, -0.6220,  0.8666]],\n",
       "\n",
       "        [[-0.6913,  1.6817, -2.8799,  ..., -0.4001, -0.6220,  0.8666],\n",
       "         [-0.6798, -0.6323, -0.1855,  ...,  0.9329, -0.2530,  0.0529],\n",
       "         [-0.2740,  0.3762,  0.0322,  ...,  0.6411,  1.0961,  2.3707],\n",
       "         ...,\n",
       "         [-0.6798, -0.6323, -0.1855,  ...,  0.9329, -0.2530,  0.0529],\n",
       "         [-1.6768,  1.1494,  0.3669,  ...,  0.2473, -0.8296, -1.1125],\n",
       "         [-0.7518,  0.9261, -0.0296,  ..., -0.8909,  0.9512,  2.0422]],\n",
       "\n",
       "        [[ 0.3380,  1.1110,  1.8421,  ..., -0.6374,  0.8257,  1.7896],\n",
       "         [-0.6798, -0.6323, -0.1855,  ...,  0.9329, -0.2530,  0.0529],\n",
       "         [-0.7518,  0.9261, -0.0296,  ..., -0.8909,  0.9512,  2.0422],\n",
       "         ...,\n",
       "         [-1.6283,  0.6991, -1.0621,  ..., -0.7243,  0.8217, -0.5025],\n",
       "         [ 0.3258, -0.1532, -0.2287,  ..., -0.5760,  0.4606,  0.1399],\n",
       "         [-0.6798, -0.6323, -0.1855,  ...,  0.9329, -0.2530,  0.0529]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
